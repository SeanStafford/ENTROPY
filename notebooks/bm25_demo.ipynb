{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BM25 Document Store Demo\n",
    "\n",
    "This notebook demonstrates the `BM25DocumentStore` class for keyword-based retrieval of financial documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from entropy.contexts.retrieval import BM25DocumentStore, YFinanceFetcher\n",
    "from entropy.utils.Seans_helpers import print_obj_map\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "load_dotenv();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refresh = True  # Set to True to force rebuild the store\n",
    "store_path = Path(os.getenv(\"DATA_PROCESSED_PATH\")) / \"bm25_store_demo.pkl\"\n",
    "\n",
    "# load existing store with previously fetched data or fetch new data and save it into a newly created store\n",
    "fetch_new_data = refresh or not os.path.exists(store_path)\n",
    "\n",
    "if fetch_new_data:\n",
    "    print(\"New data will be fetched.\")\n",
    "else:\n",
    "    print(\"Existing store found, no need to fetch new data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch from yfinance for a few example stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fetch_new_data:\n",
    "    # Fetch news from yfinance\n",
    "    tickers = [\"AAPL\", \"TSLA\", \"MSFT\", \"NVDA\"]\n",
    "    fetcher = YFinanceFetcher()\n",
    "    texts, metadata = fetcher.fetch_news(tickers)\n",
    "\n",
    "    print(f\"Fetched {len(texts)} articles across {len(tickers)} tickers\")\n",
    "else:\n",
    "    print(\"This step unnecessary because existing store found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Populate Store\n",
    "\n",
    "Initialize the BM25 document store and index the fetched articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not fetch_new_data:\n",
    "    print(f\"Loading existing store from {store_path}\")\n",
    "    store = BM25DocumentStore.load(store_path)\n",
    "else:\n",
    "    print(\"Creating new store and indexing documents...\")\n",
    "    store = BM25DocumentStore()\n",
    "    store.add_documents(texts, metadata)\n",
    "    \n",
    "    # Save for future use\n",
    "    store.save(store_path)\n",
    "    print(f\"Saved store to {store_path}\")\n",
    "\n",
    "stats = store.get_stats()\n",
    "print(f\"Documents: {stats['num_documents']}\")\n",
    "print(f\"Tickers: {', '.join(stats['tickers'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierarchical structure of `BM25DocumentStore` object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_obj_map(store, include_dicts=False, header=\"store\", max_depth=3);\n",
    "\n",
    "print(store.bm25_index.idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search with BM25\n",
    "\n",
    "Search for documents using BM25 ranking, which excels at exact term matching (ticker symbols, keywords)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_search_result_summary(results, query=None):\n",
    "\n",
    "    if query is not None:\n",
    "        print(f\"\\nQuery: '{query}'\\n\")\n",
    "\n",
    "    for i, result in enumerate(results):\n",
    "        doc = result[\"document\"]\n",
    "        score = result[\"score\"]\n",
    "        tickers = \", \".join(doc['metadata']['tickers'])\n",
    "        print(f\"{i+1}. [{tickers}] {doc['metadata']['title']}\")\n",
    "        print(f\"   Score: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"AI chips revenue\"\n",
    "\n",
    "results = store.search(query, k=5)\n",
    "\n",
    "print_search_result_summary(results, query=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment cell below to see hierarchical data structure example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_obj_map(results[0], header=\"result\", mode=\"value\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter by Ticker\n",
    "\n",
    "Search within a specific ticker symbol to narrow results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = store.search(query, k=5, filter_ticker=\"TSLA\")\n",
    "\n",
    "print_search_result_summary(results, query=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Example document tokenized:\")\n",
    "\n",
    "max_line_len = 120\n",
    "current_line = []\n",
    "current_len = 0\n",
    "\n",
    "for token in store.tokenized_corpus[0]:\n",
    "    token_str = f\"<{token}>\"\n",
    "    token_len = len(token_str) + 1  # +1 for the space\n",
    "    \n",
    "    if current_len + token_len > max_line_len and current_line:\n",
    "        print(\" \".join(current_line))\n",
    "        current_line = [token_str]\n",
    "        current_len = token_len\n",
    "    else:\n",
    "        current_line.append(token_str)\n",
    "        current_len += token_len\n",
    "\n",
    "# Print remaining tokens\n",
    "if current_line:\n",
    "    print(\" \".join(current_line))\n",
    "\n",
    "print(f\"\\nLength: {len(store.tokenized_corpus[0])} tokens\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_dict = store.bm25_index.idf\n",
    "\n",
    "labels = sorted(idf_dict, key=idf_dict.get)\n",
    "\n",
    "n_most_extreme = 10\n",
    "labels = labels[:n_most_extreme] + labels[-n_most_extreme:]\n",
    "values = [idf_dict[k] for k in labels]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(labels, values, color='skyblue')\n",
    "plt.xlabel('Terms')\n",
    "plt.ylabel('Inverse Document Frequency')\n",
    "plt.title('BM25 IDF values for most and least common terms')\n",
    "plt.xticks(rotation=45);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
